{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85271cdf",
   "metadata": {},
   "source": [
    "# **Project Overview: Predicting Income Levels Using a Deep Neural Network**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd8a8f2",
   "metadata": {},
   "source": [
    "### **1. Objective**\n",
    "This project builds a binary classification model to predict whether an individual's income exceeds $50,000 using U.S. Census data. We use a deep neural network (DNN) implemented with TensorFlow/Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7416197a",
   "metadata": {},
   "source": [
    "### **2. Data Overview**\n",
    "- Target: `income` (binary)\n",
    "- Features: Demographic and employment variables such as `age`, `education`, `occupation`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d8871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_set = pd.read_csv('USCensusTraining.csv')\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066c79ba",
   "metadata": {},
   "source": [
    "### **3. Data Cleaning & Feature Engineering**\n",
    "- Replace '?' with NaN and impute using mode\n",
    "- Drop redundant columns\n",
    "- One-hot encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4bc0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_set.replace('?', np.nan, inplace=True)\n",
    "train_set.drop('education-num', axis=1, inplace=True)\n",
    "train_set.fillna(train_set.mode().iloc[0], inplace=True)\n",
    "train_set['native-country'] = train_set['native-country'].where(train_set['native-country'] == 'United-States', 'Other')\n",
    "train_set = pd.get_dummies(train_set, drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f438517",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['income'] = np.where(train_set['income'] == '<=50K.', 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b505fc3a",
   "metadata": {},
   "source": [
    "### **4. Data Preparation**\n",
    "Split the data and apply SMOTE to handle class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afeb8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = train_set.drop('income', axis=1)\n",
    "y = train_set['income']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "smote = SMOTE(random_state=17)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c84e2f5",
   "metadata": {},
   "source": [
    "### **5. Model Architecture**\n",
    "Build and train a basic DNN with two hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68185311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(X_train.shape[1],), activation='sigmoid'))\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882d6629",
   "metadata": {},
   "source": [
    "### **6. Feature Importance**\n",
    "Extract input layer weights and compute average absolute importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b323b3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.layers[0].get_weights()[0]\n",
    "importance = np.mean(np.abs(weights), axis=1)\n",
    "features = X.columns\n",
    "\n",
    "importance_df = pd.DataFrame({'Feature': features, 'Importance': importance})\n",
    "importance_df.sort_values(by='Importance', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd481a4",
   "metadata": {},
   "source": [
    "### **7. Evaluation**\n",
    "Evaluate accuracy and display classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5828da0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "predictions = model.predict(X_train).round().astype(int)\n",
    "accuracy = accuracy_score(y_train, predictions)\n",
    "print(f\"Training Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(confusion_matrix(y_train, predictions))\n",
    "print(classification_report(y_train, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3577246",
   "metadata": {},
   "source": [
    "### **8. Hyperparameter Tuning**\n",
    "Use `GridSearchCV` with `KerasClassifier` for optimizer, batch size, and epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153e7d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def build_model(optimizer='Adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(model=build_model, verbose=0)\n",
    "param_grid = {\n",
    "    'optimizer': ['SGD', 'RMSprop', 'Adam'],\n",
    "    'batch_size': [80, 100],\n",
    "    'epochs': [50, 100]\n",
    "}\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "print(\"Best Params:\", grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaf623c",
   "metadata": {},
   "source": [
    "### **9. Test Prediction**\n",
    "Apply best model to test set and export predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52418750",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv(\"USCensusTest.csv\")\n",
    "test_set.replace('?', np.nan, inplace=True)\n",
    "test_set.fillna(test_set.mode().iloc[0], inplace=True)\n",
    "test_set.drop('education-num', axis=1, inplace=True)\n",
    "test_set['native-country'] = test_set['native-country'].where(test_set['native-country'] == 'United-States', 'Other')\n",
    "test_set = pd.get_dummies(test_set, drop_first=False)\n",
    "X_final = scaler.transform(test_set)\n",
    "predictions = grid_result.best_estimator_.predict(X_final)\n",
    "pd.DataFrame(predictions, columns=['Predictions']).to_csv('Team17_predictions.txt', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
